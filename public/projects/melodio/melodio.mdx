

FEEL IT, MAKE IT
MODULAR WORKSPACE TO EXPLORE & CREATE MUSIC
 wanted to develop an app that would help musicians create music without imposing any guidelines on the creative process. Something that could be molded by its user and adapt to the situation and skills of the musician. Break down barriers of music theory, give inspiration and axes of exploration. That is how I came up with the idea of Melodio and its Creative Pods.



 Full-stack development using React, TypeScript, and Express.js with Tailwind CSS building a responsive, user-adaptive interface designed in Figma to eliminate creative barriers for musicians of all skill levels.
Real-time audio processing Integrated Web Audio API and Meyda for real-time frequency analysis, implementing custom algorithms for note onset detection and sustained pitch recognition.

AI integration & Validation Built quality control layers that parse, validate, and format ChatGPT API responses into structured musical data, with fallback handling for edge cases and low-latency response optimization.
API performance optimization for low-latency audio recognition and AI response handling, ensuring seamless real-time interaction between user input and system output.
Scalable database architecture Designed modular data 
structures supporting future Creative Pod expansion and additional music creation tools without architectural constraints.

User-centered design philosophy  designed the system to adapt to individual workflows and skill levels, making advanced music theory accessible through intuitive, non-prescriptive tools.